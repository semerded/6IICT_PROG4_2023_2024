{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom:-35px;\">\n",
    "    <font color=#FFFFFF markdown=\"1\">\n",
    "        <h1> <center> Gebaseerd op een cursus van:</center> </h1> \n",
    "    </font>\n",
    "    <a href=\"https://www.aiopschool.be/chatbot/\"> \n",
    "        <img src=\"../_afbeeldingen/bannerugentdwengo.png\" alt=\"Dwengo\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px; width:20%\"/>\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toepassing: Deep Learning Objectdetectie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B8000\">\n",
    "In deze notebook gaan jullie aan de slag met objectdetectie. Hiervoor wordt het Deep Learning model 'YOLO' gebruikt. Objectherkenning van een afbeelding & video komen aan bod. Hiernaast ook het belang van goede trainingsdata.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Algemene info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Modules installeren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voer onderstaande code-cel uit. Het bevat de modules noodzakelijk voor deze notebook. Dit is een eenmalige actie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#8B0000\"> \n",
    "Controleert eerst dat deze notebook gebruik maakt van een venv. Vraag indien nodig aan de leerkracht om dit te controleren.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installeren van module ultralytics\n",
    "%pip install ultralytics\n",
    "# installeren van module opencv\n",
    "%pip install opencv-python\n",
    "# installeren van module matplotlib\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#000065\"> \n",
    "Tijdens deze notebook zal je gebruik maken van drie modules. ultralytics bevat het Deep Learning model dat we zullen gebruiken. OpenCV-Python maakt het mogelijk om afbeelding/video te laden & verwerken. Via matplotlib tonen we afbeeldingen in de notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Waarom Deep Learning voor objectherkenning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In notebook `1_vormdetectie.ipynb` hebben we een algoritme voor vormherkenning gemaakt. Dit algoritme was puur regelgebaseerd (AI). Waardoor we reeds snel tegen beperkingen opbotsten. Voor objectherkenning slaan we Machine Learning over, om rechtstreeks naar Deep Learning te gaan.\n",
    "\n",
    "Het is mogelijk om Machine Learning te gebruiken. Echter kunnen deze algoritmes enkel zeer specifieke zaken herkennen. De reden hiervoor zijn de beperkingen van computervisie (zie vorige notebook `1_vormdetectie.ipynb`). Deep Learning kan deze beperkingen (deels) elimineren. Dit doordat het een model opstelt met behulp van een grote hoeveelheid data.\n",
    "\n",
    "Over het algemeen kunnen we zeggen dat Deep Learning objectherkenning volgende voordelen heeft:\n",
    "- Mens hoeft niet aan te geven waar model op moet letten.\n",
    "- Verwerkt grote hoeveelheid data, waardoor complexe patronen opgesteld worden. \n",
    "- Model kan op een later moment verder trainen. Dit om het te fine-tunen voor specifieke taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Hoe trainen Deep Learning modellen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je snapt nu waarom we Deep Learning zullen gebruiken. Het is echter ook belangrijk om te weten hoe deze modellen getraind zijn.\n",
    "\n",
    "Als voorbeeld: hoe weet een Deep Learning model dat een collectie van pixels een kat is? Deep Learning modellen baseren zich vaak op de werking van het menselijk brein. De vraag is dus eigenlijk: `Hoe leert een brein het verschil tussen een kat en een hond?`\n",
    "\n",
    "Het antwoord is **oefenen**. Tijdens het trainen geven we het model een hoop data. In dit geval afbeeldingen. Bij iedere afbeelding schrijven we wat deze afbeelding is (VB. kat, hond, koe, ...). Het model begint van nul. Het krijgt een afbeelding en zal in feite gokken wat het is.\n",
    "- **Is het model juist?** Dan gebeurt er niets.\n",
    "- **Is het model fout?**  Dan zal het model zijn parameters aanpassen, zodat het de foto later wel correct herkent.\n",
    "\n",
    "Dit proces blijft zich herhalen, tot de ontwikkelaars vinden dat het model accuraat genoeg is. `Net als een mens, leren Deep Learning modellen dus door te oefenen.` Geef het genoeg voorbeelden en een model kan accuraat gokken wat er op een afbeelding staat. Om een deftige accuraatheid te bekomen, zijn er typisch duizenden voorbeelden per object nodig.\n",
    "\n",
    "Ga [naar dit artikel](https://ferhat00.medium.com/deep-learning-with-keras-classifying-cats-and-dogs-part-1-982067594856) als je meer wilt lezen over het trainen van Deep Learning modellen. Het artikel gebruikt 4000 afbeeldingen van katten en honden om een eigen kathond-detector te maken. \n",
    "\n",
    "<img src=\"../_afbeeldingen/katten.png\" alt=\"Dwengo\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px; width:30%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 YOLO -- een Deep Learning model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOLO` is een afkorting voor \"You Only Look Once\". Een populaire Deep Learning detectie-model. Het is populair omwille van zijn snelheid. Mensen kunnen in `real-time objecten detecteren`. Dit in tegenstelling tot andere modellen als `RetinaNet`.\n",
    "\n",
    "De meeste Deep Learning modellen werken in 2 stappen: \n",
    "- Eerst zoeken ze regio's waar mogelijks een object staat (en zetten hier een kader rond). \n",
    "- Vervolgens detecteren ze welk object in deze regio aanwezig is. \n",
    "\n",
    "YOLO doet deze twee stappen tegelijk. Dit is sneller, maar zorgt wel voor een lagere accuraatheid. Onderstaande grafiek geeft dit duidelijk weer. De x-as toont de snelheid van verschillende modellen, de y-as accuraatheid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_afbeeldingen/yolo.png\" alt=\"Dwengo\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px; width:40%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bovenstaande grafiek toont versie 3 van Yolo. Versie 8 is echter de laatste versie. De technologie heeft natuurlijk niet stilgezeten. Deze nieuwste versie van Yolo is zowel sneller als accurater! Door de verbeteringen is het zelfs mogelijk om het model op een [Raspberry Pi](https://docs.ultralytics.com/guides/raspberry-pi/) te gebruiken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Objectherkenning van afbeelding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Modules importeren & variabelen/functies klaarzetten "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importeer de modules `ultralytics`, `cv2` & `matplotlib` (duurt enkele seconden)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voer hierna onderstaande cel uit om het YOLOv8 model in te laden.\n",
    "<div style=\"background-color:#8B0000\"> \n",
    "De eerste keer dat je deze cel uitvoert, zal ultralytics het model downloaden. Dit kan even duren. Merk op dat het bestand grijs is in het lint links. Dit omdat het aan .gitignore is toegevoegd. Het bestand is te groot om naar GitHub te uploaden. Als je dit toch probeert, zal VS Code crashen.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO('yolov8m.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenslotte voer je onderstaande cel uit om de functie `plt_imshow` aan te maken. Deze functie toont de (verwerkte) afbeelding met `matplotlib`.\n",
    "<div style=\"background-color:#8B8000\"> \n",
    "Merk op dat deze functie reeds gebruikt is in notebook <b>1_vormdetectie.ipynb</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functie om afbeelding weer te geven.\n",
    "def plt_imshow(titel, afbeelding):\n",
    "    plt.imshow(afbeelding, cmap='Greys_r')\n",
    "    plt.title(titel)\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Welke objecten herkent Yolov8?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we eerst kijken welke objecten Yolov8 kan herkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yolo.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Beantwoord volgende vragen: <div style=\"background-color:#008000\"> \n",
    "    - Hoeveel objecten herkend YOLOv8?\n",
    "    - Noem er 3:                            \n",
    "    - In welk datatype is deze info opgeslagen?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Detecteren van een kat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voer onderstaande code-cel uit. Deze toont de afbeelding `kat.jpg`.\n",
    "<div style=\"background-color:#8B0000\"> \n",
    "Links van de code-cel staan drie puntjes. Selecteer hier de optie <b>'clear cell outputs'</b> om de afbeelding te verwijderen.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kat = cv2.imread(\"../_afbeeldingen/kat.jpg\") \n",
    "kat = cv2.cvtColor(kat, cv2.COLOR_BGR2RGB)\n",
    "plt_imshow(\"Voorbeeldafbeelding\", kat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zullen nu de kat op deze afbeelding detecteren. Hiervoor wordt onderstaande code gebruikt. Deze bestaat uit 3 stappen.\n",
    "1. Inladen afbeelding.\n",
    "2. Objecten op afbeelding detecteren & rechthoeken rond tekenen.\n",
    "3. Tonen verwerkte afbeelding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAP 1: inladen afbeelding.\n",
    "afbeelding = cv2.imread('../_afbeeldingen/kat.jpg')\n",
    "afbeelding = cv2.cvtColor(afbeelding, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# STAP 2: detecteer objecten & teken rechthoeken.\n",
    "objecten = yolo(afbeelding, verbose=False)[0]\n",
    "for object in objecten.boxes.data.tolist():\n",
    "    x1, y1, x2, y2, score, class_id = object\n",
    "    x1, y1, x2, y2, class_id = int(x1), int(y1), int(x2), int(y2), int(class_id)\n",
    "    cv2.rectangle(afbeelding, (x1, y1), (x2,y2), (0,0,255), 2)\n",
    "\n",
    "# STAP 3: tonen verwerkte afbeelding.\n",
    "plt_imshow(\"Verwerkte afbeelding\", afbeelding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wijzig bovenstaande code. Zorg dat het kader rond de kat rood is, niet blauw.\n",
    "\n",
    "- Leg uit wat de betekenis is van volgende waarden (Tip! print ze eerst) <div style=\"background-color:#008000\">\n",
    "    - class_id: \n",
    "    - score:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wijzig bovenstaande code. \n",
    "    - Zorg dat bij het kader ook staat dat een kat (*cat*) gedetecteerd is. Voeg hiervoor onderstaande regel toe aan de for-loop.\n",
    "    - Print naast het object ook hoe zeker het model is van zijn beslissing (op 2 cijfers na de komma).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Om tekst toe te voegen aan de afbeelding kan je deze code gebruiken.\n",
    "# Uitleg: zet tekst op (x,y)-positie van afbeelding met bepaalde kleur ( in [R,G,B]).\n",
    "cv2.putText(afbeelding, tekst, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, kleur, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_afbeeldingen/objectdetectie_oefenmee2.3.png\" alt=\"Dwengo\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px; width:15%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 2.4\n",
    "- In `oefen mee 2.3` zette je altijd kat (*cat*) bij het kader. Dit werkt natuurlijk enkel voor deze afbeelding. Zorg ervoor dat bij ieder gedetecteerd object de correcte naam staat. Gebruik hiervoor `yolo.names` uit deel 3.2, in combinatie met `class_id`. Hieronder enkele afbeeldingen waarmee je kan testen.\n",
    "    - **../_afbeeldingen/auto.jpg**: een *truck*.\n",
    "    - **../_afbeeldingen/fietsen.jpg**: twee *bicycles*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze afbeeldingen verwerken, moet volgend resultaat geven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_afbeeldingen/objectdetectie_oefenmee2.4.png\" alt=\"Dwengo\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px; width:60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Objectherkenning filteren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tijdens dit onderdeel gebruiken we volgende afbeelding. Het toont een aantal mensen die in het park picnicken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_afbeeldingen/park_picnic.jpg\" alt=\"Dwengo\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px; width:30%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Modules importeren & variabelen/functies klaarzetten "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importeer de modules `ultralytics`, `cv2` & `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voer hierna onderstaande cel uit om het YOLOv8 model in te laden.\n",
    "<div style=\"background-color:#8B0000\"> \n",
    "De eerste keer dat je deze cel uitvoert, zal ultralytics het model downloaden. Dit kan even duren. Het bestand is ook te groot om naar GitHub te uploaden. Daarom is het toegevoegd aan .gitignore.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO('yolov8m.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenslotte Voer je onderstaande cel uit om de functie `plt_imshow` aan te maken. Deze functie toont de (verwerkte) afbeelding met `matplotlib`.\n",
    "<div style=\"background-color:#8B8000\"> \n",
    "Merk op dat deze functie reeds gebruikt is in notebook <b>1_vormdetectie.ipynb</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functie om afbeelding weer te geven.\n",
    "def plt_imshow(titel, afbeelding):\n",
    "    plt.imshow(afbeelding, cmap='Greys_r')\n",
    "    plt.title(titel)\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Enkel specifieke objecten herkennen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bekijk onderstaande code, voer deze uit en beantwoord vervolgens de vragen. <div style=\"background-color:#008000\">\n",
    "    - Hoe bepaald de code hoeveel personen er aanwezig zijn:\n",
    "    - Deze methode werkt niet. Leg uit waarom:\n",
    "</div>\n",
    "\n",
    "- Pas de code aan om dit probleem op te lossen. Zorg er ook voor dat enkel kaders rond mensen staan\n",
    "<div style=\"background-color:#8B0000\"> \n",
    "Enkel ALS het object een persoon is, teken er een kader rond en verhoog de teller. <b>class_id</b> geeft aan wat voor soort object gevonden is. Ga terug naar <b>deel 2.2</b> voor meer info.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aantal = 0\n",
    "\n",
    "# STAP 1: inladen afbeelding.\n",
    "afbeelding = cv2.imread('../_afbeeldingen/park_picnic.jpg')\n",
    "afbeelding = cv2.cvtColor(afbeelding, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# STAP 2: detecteer objecten & teken rechthoeken.\n",
    "objecten = yolo(afbeelding, verbose=False)[0]\n",
    "for object in objecten.boxes.data.tolist():\n",
    "    x1, y1, x2, y2, score, class_id = object\n",
    "    x1, y1, x2, y2, class_id = int(x1), int(y1), int(x2), int(y2), int(class_id)\n",
    "    cv2.rectangle(afbeelding, (x1, y1), (x2,y2), (0,0,255), 2)\n",
    "    aantal = aantal+1\n",
    "\n",
    "# STAP 3: tonen verwerkte afbeelding.\n",
    "plt_imshow(f\"Personen: {aantal}\", afbeelding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Enkel nauwkeurig objecten herkennen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na het uitvoeren van `oefen mee 3.1` zijn er kaders getekend rond wat het model denkt dat mensen zijn... Echter hoe zeker is het model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plaats in onderstaande kader de aangepaste code van `oefen mee 3.1`.\n",
    "- Voeg code toe zodat voor iedere persoon ook de accuraatheid (score) geprint wordt. Afgerond op 2 cijfers na de komma.\n",
    "- Voeg code toe zodat enkel personen met een accuraatheid boven 0,4 een kader rond zicht krijgen en de teller verhogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: vul aan met code uit oefen mee 3.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Op het einde van deze oefen mee moet de afbeelding er als volgt uitzien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../_afbeeldingen/objectdetectie_oefenmee3.2.png\" alt=\"Dwengo\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px; width:30%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plaats in onderstaande kader de aangepaste code van `oefen mee 3.2`.\n",
    "\n",
    "- Vraag aan de gebruiker hoe nauwkeurig het algoritme moet optreden. Er zijn drie keuzen:\n",
    "    - \"niet\": laat alle personen door.\n",
    "    - \"gemiddeld\": alle personen met een score hoger dan 0,4.\n",
    "    - \"strict\": alle personen met een score hoger dan 0,8.\n",
    "\n",
    "- (optioneel) zoek zelf een aantal afbeeldingen op en pas er dit algoritme op toe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: vul aan met code uit oefen mee 3.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Objectherkenning van video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tijdens dit onderdeel, zal onderstaande video gebruikt worden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video width=\"320\" height=\"240\" controls style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px\">\n",
    "  <source src=\"../_afbeeldingen/snelweg.mp4\" type=\"video/mp4\" >\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modules importeren & variabelen klaarzetten "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importeer de modules `ultralytics`, `cv2`.\n",
    "\n",
    "<div style=\"background-color:#8B0000\"> \n",
    "Merk op dat <b>matplotlib</b> niet aanwezig is. Video's tonen via deze module is niet mogelijk. We gebruiken daarom een functionaliteit ingebouwd in <b>OpenCV</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voer hierna onderstaande cel uit om het YOLOv8 model in te laden.\n",
    "<div style=\"background-color:#8B0000\"> \n",
    "De eerste keer dat je deze cel uitvoert, zal ultralytics het model downloaden. Dit kan even duren. Het bestand is ook te groot om naar GitHub te uploaden. Daarom is het toegevoegd aan .gitignore.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO('yolov8m.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Video splitsen in frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een video bestaat uit een hoop afbeeldingen (frames) die snel achter elkaar afgespeeld worden. Objectdetectie op een video, betekent eigenlijk objectdetectie toepassen op ieder frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bekijk onderstaande code. Via OpenCV klasse `VideoCapture` laden we een video in. De methode `read` haalt het volgende frame op van de video.\n",
    "<div style=\"background-color:#8B0000\"> \n",
    "Druk op <b>'q'</b> om de video vroegtijdig te stoppen. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stap 1: inladen video.\n",
    "video = cv2.VideoCapture('../_afbeeldingen/snelweg.mp4')\n",
    "\n",
    "while True:\n",
    "    # Stap 2: haal ieder frame uit de video.\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break # (stop als alle frames overlopen zijn)\n",
    "\n",
    "\n",
    "    # STAP 3: detecteer objecten & teken rechthoeken.\n",
    "    frame = cv2.resize(frame, (780, 540), interpolation = cv2.INTER_LINEAR)\n",
    "    # TODO: VUL AAN MET CODE OBJECTHERKENNING \n",
    "\n",
    "\n",
    "    # Stap 4: tonen verwerkte frame.\n",
    "    cv2.imshow(\"Snelweg\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'): # Duw op 'q' om video eerder te stoppen.\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows() # Sluit braaf het laatst getoonde frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bovenstaande code is nog niet volledig. In deze oefen mee pas je bovenstaande code-cel aan.\n",
    "- Vul de todo aan zodat er aan object herkenning gedaan wordt. Er moeten kaders verschijnen rond alle gedetecteerde objecten. Je mag zelf kiezen welke kleur. Baseer je hiervoor op de code uit **deel 2 en deel 3**\n",
    "\n",
    "- Pas de code verder aan. Zorg ervoor dat enkel gedetecteerde voertuigen omkaderd worden. Ga zelf na welke *class_id* overeenkomen met voertuigen.\n",
    "<div style=\"background-color:#8B0000\"> \n",
    "Voor meer info over de <b>class_id</b>. Ga terug naar <b>deel 2.2</b>.\n",
    "</div>\n",
    "\n",
    "- Voeg onderstaande code toe boven `cv2.imshow(...)`. Het voegt tekst toe aan het frame. Verander **VUL_AAN** door het aantal gedetecteerde voertuigen.\n",
    "<div style=\"background-color:#8B0000\"> \n",
    "Voor meer info over het tellen van objecten. Ga terug naar <b>deel 3.2</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.putText(frame, f\"Aantal voertuigen: {VUL_AAN}\", (7,70),  cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onderstaande afbeelding is een frame bekomen na het afwerken van bovenstaande drie stappen.<br><br>\n",
    "<img src=\"../_afbeeldingen/objectdetectie_oefenmee4.1.png\" alt=\"Dwengo\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px; width:20%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Framerate van objectdetectie (Extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het is opgevallen dat de video afspelen zonder objectdetectie sneller is, dan met objectdetectie. De vraag is enkel, hoeveel sneller? Dit bepalen we door de FPS (Frames Per Second) te tonen op het scherm. FPS geeft aan hoeveel frames van de video de computer per seconde kan afspelen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 4.2\n",
    "Vertrek vanuit onderstaande code. \n",
    "- Neem de code uit oefen mee 4.1 hier over.\n",
    "\n",
    "- Voeg aan ieder frame tekst toe met erin de FPS. [Deze tutorial](https://www.geeksforgeeks.org/python-displaying-real-time-fps-at-which-webcam-video-file-is-processed-using-opencv/) legt uit hoe de FPS te berekenen.\n",
    "\n",
    "- Vergelijk de FPS van de video zonder & met objectherkenning.  <div style=\"background-color:#008000\">\n",
    "    - Hoeveel trager is de video bij gebruik van objectherkenning?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: vul aan met code uit oefen mee 4.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Belang van een goede dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de vorige delen is gezien dat YOLO er in slaagt om objecten te herkennen op eenvoudige afbeeldingen. In dit deel tonen we aan dat het model echter verre van perfect is. Dit om duidelijk te maken dat de ontwikkelaar nog altijd goed moet nadenken over hoe een Deep Learning model te gebruiken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Modules importeren & variabelen/functies klaarzetten "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importeer de modules `ultralytics`, `cv2`, `matplotlib` & `random`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voer hierna onderstaande cel uit om het YOLOv8 model in te laden.\n",
    "<div style=\"background-color:#8B0000\"> \n",
    "De eerste keer dat je deze cel uitvoert, zal ultralytics het model downloaden. Dit kan even duren.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO('yolov8m.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenslotte Voer je onderstaande cel uit om de functie `plt_imshow` aan te maken. Deze functie toont de (verwerkte) afbeelding met `matplotlib`.\n",
    "<div style=\"background-color:#8B8000\"> \n",
    "Merk op dat deze functie reeds gebruikt is in notebook <b>1_vormdetectie.ipynb</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functie om afbeelding weer te geven.\n",
    "def plt_imshow(titel, afbeelding):\n",
    "    plt.imshow(afbeelding, cmap='Greys_r')\n",
    "    plt.title(titel)\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 De afbeelding `hondkat.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eerst bekijken we een afbeelding met erop een aantal honden en katten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Voer onderstaande cel uit.<div style=\"background-color:#008000\">\n",
    "    - Hoeveel honden tel jij:\n",
    "    - Hoeveel katten tel jij:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afbeelding = cv2.imread(\"../_afbeeldingen/hondkat.png\") \n",
    "afbeelding = cv2.cvtColor(afbeelding, cv2.COLOR_BGR2RGB)\n",
    "plt_imshow(\"Hondkat\", afbeelding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Laat nu het model los op deze afbeelding (voer volgende code-cel uit). <div style=\"background-color:#008000\">\n",
    "    - Hoeveel fouten maakt het model:\n",
    "    - Waarom denk je dat het deze fouten (als er fouten zijn):\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#8B0000\"> \n",
    "Merk de variabele <b>kleuren</b> op. Deze bevat een willekeurige kleur voor ieder object in het YOLO-model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kleuren = [random.choices(range(256), k=3) for _ in range(len(yolo.names))]\n",
    "\n",
    "# STAP 1: inladen afbeelding.\n",
    "afbeelding = cv2.imread(\"../_afbeeldingen/hondkat.png\")\n",
    "afbeelding = cv2.cvtColor(afbeelding, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# STAP 2: detecteer objecten & teken rechthoeken.\n",
    "objecten = yolo(afbeelding, verbose=False)[0]\n",
    "for object in objecten.boxes.data.tolist():\n",
    "    x1, y1, x2, y2, score, class_id = object\n",
    "    x1, y1, x2, y2, class_id = int(x1), int(y1), int(x2), int(y2), int(class_id)\n",
    "    cv2.rectangle(afbeelding, (x1, y1), (x2,y2), kleuren[class_id], 2)\n",
    "    cv2.putText(afbeelding, f\"{yolo.names[class_id]}:{round(score,2)}\", (x1+5, y1+30), cv2.FONT_HERSHEY_SIMPLEX, 1, kleuren[class_id], 2)\n",
    "\n",
    "# STAP 3: tonen verwerkte afbeelding.\n",
    "plt_imshow(\"Hondkat verwerkt\", afbeelding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 De afbeelding `hondcake.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu bekijken we een afbeelding met erop een aantal X en Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oefen mee 5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Voer onderstaande cel uit. Het bevat een afbeelding met erop honden & katten. <div style=\"background-color:#008000\">\n",
    "    - Hoeveel honden tel jij:\n",
    "    - Hoeveel cupcakes tel jij:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afbeelding = cv2.imread(\"../_afbeeldingen/hondcake.png\") \n",
    "afbeelding = cv2.cvtColor(afbeelding, cv2.COLOR_BGR2RGB)\n",
    "plt_imshow(\"Hondkat\", afbeelding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Laat nu het model los op deze afbeelding (voer volgende code-cel uit). <div style=\"background-color:#008000\">\n",
    "    - Hoeveel fouten maakt het model:\n",
    "    - Waarom denk je dat het deze fouten (als er fouten zijn):\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#8B0000\"> \n",
    "Merk de variabele <b>kleuren</b> op. Deze bevat een willekeurige kleur voor ieder object in het YOLO-model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kleuren = [random.choices(range(256), k=3) for _ in range(len(yolo.names))]\n",
    "\n",
    "# STAP 1: Inladen afbeelding\n",
    "afbeelding = cv2.imread(\"../_afbeeldingen/hondcake.png\")\n",
    "afbeelding = cv2.cvtColor(afbeelding, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# STAP 2: detecteer objecten & teken rechthoeken.\n",
    "objecten = yolo(afbeelding, verbose=False)[0]\n",
    "for object in objecten.boxes.data.tolist():\n",
    "    x1, y1, x2, y2, score, class_id = object\n",
    "    x1, y1, x2, y2, class_id = int(x1), int(y1), int(x2), int(y2), int(class_id)\n",
    "    cv2.rectangle(afbeelding, (x1, y1), (x2,y2), kleuren[class_id], 2)\n",
    "    cv2.putText(afbeelding, f\"{yolo.names[class_id]}:{round(score,2)}\", (x1+5, y1+30), cv2.FONT_HERSHEY_SIMPLEX, 1, kleuren[class_id], 2)\n",
    "\n",
    "# STAP 3: Tonen verwerkte afbeelding.\n",
    "plt_imshow(\"Verwerkte afbeelding\", afbeelding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Conclusie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een DL-model wordt getraind a.d.h.v. voorbeelden (ook wel een `dataset` genoemd). Een goede dataset bevat veel voorbeelden van alle zaken die het algoritme moet onderscheiden.\n",
    "\n",
    "Stel dat je de `tomaten in je moestuin wilt herkennen`. Je neemt eerst heel wat foto's van tomaten. Waarna je deze foto's aan het model geeft, met op iedere afbeelding het label 'tomaat'. Het model zoekt dan zelf kenmerken die op elke foto voorkomen, bijvoorbeeld dat de `tomaat rond is en rood`. Plots merk je dat je systeem compleet ontregeld is, blijkbaar waren kinderen met een `rode bal´ in het beeld van de camera aan het spelen...\n",
    "\n",
    "Als een ander voorwerp sterk lijkt op hetgeen jij wilt detecteren, dan kan dat ertoe leiden dat het model fouten maakt. Hetzelfde gebeurde in bovenstaande afbeelding. Om dit te voorkomen, moet je altijd goed nadenken over welke objecten allemaal in jouw omgeving zullen voorkomen. Het model moet getraind zijn om het verschil ertussen te zien!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voorwerpen die sterk op elkaar lijken zijn een probleem waar zelf de beste *machine learning* en *deep learning* algoritmes nog op vast lopen. Dit toont dan ook het nut aan van een **uitgebreide en gevarieerde dataset**. \n",
    "\n",
    "Nog een aantal voorbeelden van afbeeldingen waar veel algoritmes op vast lopen zijn. Alle voorbeelden uit deze Notebook zijn niet realistisch, maar duiden wel het gevaar aan van een beperkte dataset. beeld je eens in dat iets soortgelijks zou gebeuren met een zelfrijdende wagen?\n",
    "<table><tr>\n",
    "<td><figure>\n",
    "  <img src=\"../_afbeeldingen/hondkip.jpg\" alt=\"Trulli\" width=\"200\">\n",
    "    <figcaption><center>Hond of crispy chicken</center></figcaption>\n",
    "</figure></td>\n",
    "<td><figure>\n",
    "  <img src=\"../_afbeeldingen/hondmop.jpg\" alt=\"Trulli\" width=\"200\">\n",
    "    <figcaption><center>Hond of mop</center></figcaption>\n",
    "</figure></td>\n",
    "<td><figure>\n",
    "  <img src=\"../_afbeeldingen/slotchocoladekoek.jpg\" alt=\"Trulli\" width=\"200\">\n",
    "    <figcaption><center>Chocoladekoek of luiaard</center></figcaption>\n",
    "</figure></td>\n",
    "<td><figure>\n",
    "  <img src=\"../_afbeeldingen/corgibrood.png\" alt=\"Trulli\" width=\"200\">\n",
    "    <figcaption><center>Corgi of brood</center></figcaption>\n",
    "</figure> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "  <a href=\"https://www.aiopschool.be/chatbot/\"> \n",
    "        <img src=\"../_afbeeldingen/bannerugentdwengo.png\" alt=\"Dwengo\" style =\"display: block; margin-left: auto; margin-right: auto; margin-bottom: 30px; width:20%\"/>\n",
    "    </a>\n",
    "\n",
    "Deze Notebook is gebaseerd op: Notebook AI in de Landbouw, zie <a href=\"http://www.aiopschool.be\">AI Op School</a>, van S. Pletinck , F. wyffels & N. Gesquière is in licentie gegeven volgens een <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Naamsvermelding-NietCommercieel-GelijkDelen 4.0 Internationaal-licentie</a>. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prog4",
   "language": "python",
   "name": "prog4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
